{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66b5235-b1e8-46fe-9849-2a7e99a1c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hcw-00/PatchCore_anomaly_detection\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from utils.kcenter_greedy import kCenterGreedy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import shutil\n",
    "import faiss\n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from utils.kcenter_greedy import kCenterGreedy\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "def distance_matrix(x, y=None, p=2):  # pairwise distance of vectors\n",
    "\n",
    "    y = x if type(y) == type(None) else y\n",
    "\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    dist = torch.pow(x - y, p).sum(2)\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "class Id():\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "class NN():\n",
    "\n",
    "    def __init__(self, X=None, Y=None, p=2):\n",
    "        self.p = p\n",
    "        self.train(X, Y)\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        self.train_pts = X\n",
    "        self.train_label = Y\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.predict(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if type(self.train_pts) == type(None) or type(self.train_label) == type(None):\n",
    "            name = self.__class__.__name__\n",
    "            raise RuntimeError(f\"{name} wasn't trained. Need to execute {name}.train() first\")\n",
    "\n",
    "        dist = distance_matrix(x, self.train_pts, self.p) ** (1 / self.p)\n",
    "        labels = torch.argmin(dist, dim=1)\n",
    "        return self.train_label[labels]\n",
    "\n",
    "class KNN(NN):\n",
    "\n",
    "    def __init__(self, X=None, Y=None, k=3, p=2):\n",
    "        self.k = k\n",
    "        super().__init__(X, Y, p)\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        super().train(X, Y)\n",
    "        if type(Y) != type(None):\n",
    "            self.unique_labels = self.train_label.unique()\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "\n",
    "        # dist = distance_matrix(x, self.train_pts, self.p) ** (1 / self.p)\n",
    "        dist = torch.cdist(x, self.train_pts, self.p)\n",
    "\n",
    "        knn = dist.topk(self.k, largest=False)\n",
    "\n",
    "\n",
    "        return knn\n",
    "\n",
    "def copy_files(src, dst, ignores=[]):\n",
    "    src_files = os.listdir(src)\n",
    "    for file_name in src_files:\n",
    "        ignore_check = [True for i in ignores if i in file_name]\n",
    "        if ignore_check:\n",
    "            continue\n",
    "        full_file_name = os.path.join(src, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, os.path.join(dst,file_name))\n",
    "        if os.path.isdir(full_file_name):\n",
    "            os.makedirs(os.path.join(dst, file_name), exist_ok=True)\n",
    "            copy_files(full_file_name, os.path.join(dst, file_name), ignores)\n",
    "\n",
    "def prep_dirs(root):\n",
    "    # make embeddings dir\n",
    "    # embeddings_path = os.path.join(root, 'embeddings')\n",
    "    embeddings_path = os.path.join('./', 'embeddings', args.category)\n",
    "    os.makedirs(embeddings_path, exist_ok=True)\n",
    "    # make sample dir\n",
    "    sample_path = os.path.join(root, 'sample')\n",
    "    os.makedirs(sample_path, exist_ok=True)\n",
    "    # make source code record dir & copy\n",
    "    source_code_save_path = os.path.join(root, 'src')\n",
    "    os.makedirs(source_code_save_path, exist_ok=True)\n",
    "    copy_files('./', source_code_save_path, ['.git','.vscode','__pycache__','logs','README','samples','LICENSE']) # copy source code\n",
    "    return embeddings_path, sample_path, source_code_save_path\n",
    "\n",
    "def embedding_concat(x, y):\n",
    "    # from https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master\n",
    "    B, C1, H1, W1 = x.size()\n",
    "    _, C2, H2, W2 = y.size()\n",
    "    s = int(H1 / H2)\n",
    "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
    "    x = x.view(B, C1, -1, H2, W2)\n",
    "    z = torch.zeros(B, C1 + C2, x.size(2), H2, W2)\n",
    "    for i in range(x.size(2)):\n",
    "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), 1)\n",
    "    z = z.view(B, -1, H2 * W2)\n",
    "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
    "\n",
    "    return z\n",
    "\n",
    "def reshape_embedding(embedding):\n",
    "    embedding_list = []\n",
    "    for k in range(embedding.shape[0]):\n",
    "        for i in range(embedding.shape[2]):\n",
    "            for j in range(embedding.shape[3]):\n",
    "                embedding_list.append(embedding[k, :, i, j])\n",
    "    return embedding_list\n",
    "\n",
    "#imagenet\n",
    "mean_train = [0.485, 0.456, 0.406]\n",
    "std_train = [0.229, 0.224, 0.225]\n",
    "\n",
    "class MVTecDataset(Dataset):\n",
    "    def __init__(self, root, transform, gt_transform, phase):\n",
    "        if phase=='train':\n",
    "            self.img_path = os.path.join(root, 'train')\n",
    "        else:\n",
    "            self.img_path = os.path.join(root, 'test')\n",
    "            self.gt_path = os.path.join(root, 'ground_truth')\n",
    "        self.transform = transform\n",
    "        self.gt_transform = gt_transform\n",
    "        # load dataset\n",
    "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset() # self.labels => good : 0, anomaly : 1\n",
    "\n",
    "    def load_dataset(self):\n",
    "\n",
    "        img_tot_paths = []\n",
    "        gt_tot_paths = []\n",
    "        tot_labels = []\n",
    "        tot_types = []\n",
    "        \n",
    "        print( self.img_path )\n",
    "        defect_types = os.listdir(self.img_path)\n",
    "        \n",
    "        for defect_type in defect_types:\n",
    "            if defect_type == 'good':\n",
    "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\")\n",
    "                img_tot_paths.extend(img_paths)\n",
    "                gt_tot_paths.extend([0]*len(img_paths))\n",
    "                tot_labels.extend([0]*len(img_paths))\n",
    "                tot_types.extend(['good']*len(img_paths))\n",
    "            else:\n",
    "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\")\n",
    "                gt_paths = glob.glob(os.path.join(self.gt_path, defect_type) + \"/*.png\")\n",
    "                img_paths.sort()\n",
    "                gt_paths.sort()\n",
    "                img_tot_paths.extend(img_paths)\n",
    "                gt_tot_paths.extend(gt_paths)\n",
    "                tot_labels.extend([1]*len(img_paths))\n",
    "                tot_types.extend([defect_type]*len(img_paths))\n",
    "\n",
    "        assert len(img_tot_paths) == len(gt_tot_paths), \"Something wrong with test and ground truth pair!\"\n",
    "        \n",
    "        return img_tot_paths, gt_tot_paths, tot_labels, tot_types\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        if gt == 0:\n",
    "            gt = torch.zeros([1, img.size()[-2], img.size()[-2]])\n",
    "        else:\n",
    "            gt = Image.open(gt)\n",
    "            gt = self.gt_transform(gt)\n",
    "        \n",
    "        assert img.size()[1:] == gt.size()[1:], \"image.size != gt.size !!!\"\n",
    "\n",
    "        # print(\"Normalize DC and Contrast\")\n",
    "        img = img - img.flatten().mean().reshape(1, 1, 1)\n",
    "        img = img / torch.norm(img.flatten()).reshape(1, 1, 1)\n",
    "        \n",
    "        \n",
    "        return img, gt, label, os.path.basename(img_path[:-4]), img_type\n",
    "\n",
    "\n",
    "def cvt2heatmap(gray):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(gray), cv2.COLORMAP_JET)\n",
    "    return heatmap\n",
    "\n",
    "def heatmap_on_image(heatmap, image):\n",
    "    if heatmap.shape != image.shape:\n",
    "        heatmap = cv2.resize(heatmap, (image.shape[0], image.shape[1]))\n",
    "    out = np.float32(heatmap)/255 + np.float32(image)/255\n",
    "    out = out / np.max(out)\n",
    "    return np.uint8(255 * out)\n",
    "\n",
    "def min_max_norm(image):\n",
    "    a_min, a_max = image.min(), image.max()\n",
    "    return (image-a_min)/(a_max - a_min)    \n",
    "\n",
    "\n",
    "def cal_confusion_matrix(y_true, y_pred_no_thresh, thresh, img_path_list):\n",
    "    pred_thresh = []\n",
    "    false_n = []\n",
    "    false_p = []\n",
    "    for i in range(len(y_pred_no_thresh)):\n",
    "        if y_pred_no_thresh[i] > thresh:\n",
    "            pred_thresh.append(1)\n",
    "            if y_true[i] == 0:\n",
    "                false_p.append(img_path_list[i])\n",
    "        else:\n",
    "            pred_thresh.append(0)\n",
    "            if y_true[i] == 1:\n",
    "                false_n.append(img_path_list[i])\n",
    "\n",
    "    cm = confusion_matrix(y_true, pred_thresh)\n",
    "    print(cm)\n",
    "    print('false positive')\n",
    "    print(false_p)\n",
    "    print('false negative')\n",
    "    print(false_n)\n",
    "    \n",
    "\n",
    "class STPM(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(STPM, self).__init__()\n",
    "\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "        self.init_features()\n",
    "        def hook_t(module, input, output):\n",
    "            self.features.append(output)\n",
    "\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.9.0', 'wide_resnet50_2', pretrained=True)\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.model.layer2[-1].register_forward_hook(hook_t)\n",
    "        self.model.layer3[-1].register_forward_hook(hook_t)\n",
    "\n",
    "        self.criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "        self.init_results_list()\n",
    "\n",
    "        self.data_transforms = transforms.Compose([\n",
    "                        transforms.Resize((args.load_size, args.load_size), Image.ANTIALIAS),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.CenterCrop(args.input_size),\n",
    "                        transforms.Normalize(mean=mean_train,\n",
    "                                            std=std_train)])\n",
    "        self.gt_transforms = transforms.Compose([\n",
    "                        transforms.Resize((args.load_size, args.load_size)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.CenterCrop(args.input_size)])\n",
    "\n",
    "        self.inv_normalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255], std=[1/0.229, 1/0.224, 1/0.255])\n",
    "\n",
    "    def init_results_list(self):\n",
    "        self.gt_list_px_lvl = []\n",
    "        self.pred_list_px_lvl = []\n",
    "        self.gt_list_img_lvl = []\n",
    "        self.pred_list_img_lvl = []\n",
    "        self.img_path_list = []        \n",
    "\n",
    "    def init_features(self):\n",
    "        self.features = []\n",
    "\n",
    "    def forward(self, x_t):\n",
    "        self.init_features()\n",
    "        _ = self.model(x_t)\n",
    "        return self.features\n",
    "\n",
    "    def save_anomaly_map(self, anomaly_map, input_img, gt_img, file_name, x_type):\n",
    "        if anomaly_map.shape != input_img.shape:\n",
    "            anomaly_map = cv2.resize(anomaly_map, (input_img.shape[0], input_img.shape[1]))\n",
    "        anomaly_map_norm = min_max_norm(anomaly_map)\n",
    "        anomaly_map_norm_hm = cvt2heatmap(anomaly_map_norm*255)\n",
    "\n",
    "        # anomaly map on image\n",
    "        heatmap = cvt2heatmap(anomaly_map_norm*255)\n",
    "        hm_on_img = heatmap_on_image(heatmap, input_img)\n",
    "\n",
    "        # save images\n",
    "        cv2.imwrite(os.path.join(self.sample_path, f'{x_type}_{file_name}.jpg'), input_img)\n",
    "        cv2.imwrite(os.path.join(self.sample_path, f'{x_type}_{file_name}_amap.jpg'), anomaly_map_norm_hm)\n",
    "        cv2.imwrite(os.path.join(self.sample_path, f'{x_type}_{file_name}_amap_on_img.jpg'), hm_on_img)\n",
    "        cv2.imwrite(os.path.join(self.sample_path, f'{x_type}_{file_name}_gt.jpg'), gt_img)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        image_datasets = MVTecDataset(root=os.path.join(args.dataset_path,args.category), transform=self.data_transforms, gt_transform=self.gt_transforms, phase='train')\n",
    "        train_loader = DataLoader(image_datasets, batch_size=args.batch_size, shuffle=True, num_workers=0) #, pin_memory=True)\n",
    "        return train_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_datasets = MVTecDataset(root=os.path.join(args.dataset_path,args.category), transform=self.data_transforms, gt_transform=self.gt_transforms, phase='test')\n",
    "        test_loader = DataLoader(test_datasets, batch_size=1, shuffle=False, num_workers=0) #, pin_memory=True) # only work on batch_size=1, now.\n",
    "        return test_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return None\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self.model.eval() # to stop running_var move (maybe not critical)\n",
    "        self.embedding_dir_path, self.sample_path, self.source_code_save_path = prep_dirs(self.logger.log_dir)\n",
    "        self.embedding_list = []\n",
    "    \n",
    "    def on_test_start(self):\n",
    "        return\n",
    "        self.index = faiss.read_index(os.path.join(self.embedding_dir_path,'index.faiss'))\n",
    "        if torch.cuda.is_available():\n",
    "            res = faiss.StandardGpuResources()\n",
    "            self.index = faiss.index_cpu_to_gpu(res, 0 ,self.index)\n",
    "        self.init_results_list()\n",
    "        self.embedding_dir_path, self.sample_path, self.source_code_save_path = prep_dirs(self.logger.log_dir)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx): # save locally aware patch features\n",
    "        x, _, _, file_name, _ = batch\n",
    "        features = self(x)\n",
    "        embeddings = []\n",
    "        for feature in features:\n",
    "            m = torch.nn.AvgPool2d(3, 1, 1)\n",
    "            embeddings.append(m(feature))\n",
    "        embedding = embedding_concat(embeddings[0], embeddings[1])\n",
    "        self.embedding_list.extend(reshape_embedding(np.array(embedding)))\n",
    "\n",
    "    def training_epoch_end(self, outputs): \n",
    "        total_embeddings = np.array(self.embedding_list)\n",
    "        # Random projection\n",
    "        self.randomprojector = SparseRandomProjection(n_components='auto', eps=0.9) # 'auto' => Johnson-Lindenstrauss lemma\n",
    "        self.randomprojector.fit(total_embeddings)\n",
    "        print(\"Johnson-Lindenstrauss lemma n_components\", self.randomprojector.n_components)\n",
    "\n",
    "        # Coreset Subsampling\n",
    "        selector = kCenterGreedy(total_embeddings, 0, 0)\n",
    "        selected_idx = selector.select_batch(model=self.randomprojector, already_selected=[], N=int(total_embeddings.shape[0]*args.coreset_sampling_ratio))\n",
    "        # print(selected_idx, int(total_embeddings.shape[0]*args.coreset_sampling_ratio))\n",
    "        self.embedding_coreset = total_embeddings[selected_idx]\n",
    "        \n",
    "        print('initial embedding size : ', total_embeddings.shape)\n",
    "        print('final embedding size : ', self.embedding_coreset.shape)\n",
    "        \n",
    "        # np.save(\"./embeddings/screw/total_embeddings.npy\", total_embeddings) \n",
    "        # np.save(\"./embeddings/screw/core_embeddings.npy\", self.embedding_coreset) \n",
    "        #faiss\n",
    "        self.index = faiss.IndexFlatL2(self.embedding_coreset.shape[1])\n",
    "        self.index.add(self.embedding_coreset) \n",
    "        faiss.write_index(self.index,  os.path.join(self.embedding_dir_path,'index.faiss'))\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx): # Nearest Neighbour Search\n",
    "        x, gt, label, file_name, x_type = batch\n",
    "        # extract embedding\n",
    "        features = self(x)\n",
    "        embeddings = []\n",
    "        for feature in features:\n",
    "            m = torch.nn.AvgPool2d(3, 1, 1)\n",
    "            embeddings.append(m(feature))\n",
    "        embedding_ = embedding_concat(embeddings[0], embeddings[1])\n",
    "        embedding_test = np.array(reshape_embedding(np.array(embedding_)))\n",
    "        #np.save(f\"./embeddings/screw/test_embeddings_{batch_idx}.npy\", embedding_test) \n",
    "        #np.save(f\"./embeddings/screw/test_label_{batch_idx}.npy\", label.cpu().numpy()) \n",
    "        \n",
    "        \n",
    "        score_patches, _ = self.index.search(embedding_test , k=args.n_neighbors)\n",
    "        anomaly_map = score_patches[:,0].reshape((28,28))\n",
    "        N_b = score_patches[np.argmax(score_patches[:,0])]\n",
    "        w = (1 - (np.max(np.exp(N_b))/np.sum(np.exp(N_b))))\n",
    "        score = w*max(score_patches[:,0]) # Image-level score\n",
    "        gt_np = gt.cpu().numpy()[0,0].astype(int)\n",
    "        anomaly_map_resized = cv2.resize(anomaly_map, (args.input_size, args.input_size))\n",
    "        anomaly_map_resized_blur = gaussian_filter(anomaly_map_resized, sigma=4)\n",
    "        self.gt_list_px_lvl.extend(gt_np.ravel())\n",
    "        self.pred_list_px_lvl.extend(anomaly_map_resized_blur.ravel())\n",
    "        self.gt_list_img_lvl.append(label.cpu().numpy()[0])\n",
    "        self.pred_list_img_lvl.append(score)\n",
    "        self.img_path_list.extend(file_name)\n",
    "        # save images\n",
    "        x = self.inv_normalize(x)\n",
    "        input_x = cv2.cvtColor(x.permute(0,2,3,1).cpu().numpy()[0]*255, cv2.COLOR_BGR2RGB)\n",
    "        self.save_anomaly_map(anomaly_map_resized_blur, input_x, gt_np*255, file_name[0], x_type[0])\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        print(\"Total pixel-level auc-roc score :\")\n",
    "        pixel_auc = roc_auc_score(self.gt_list_px_lvl, self.pred_list_px_lvl)\n",
    "        print(pixel_auc)\n",
    "        print(\"Total image-level auc-roc score :\")\n",
    "        img_auc = roc_auc_score(self.gt_list_img_lvl, self.pred_list_img_lvl)\n",
    "        print(img_auc)\n",
    "        print('test_epoch_end')\n",
    "        values = {'pixel_auc': pixel_auc, 'img_auc': img_auc}\n",
    "        self.log_dict(values)\n",
    "        # anomaly_list = []\n",
    "        # normal_list = []\n",
    "        # for i in range(len(self.gt_list_img_lvl)):\n",
    "        #     if self.gt_list_img_lvl[i] == 1:\n",
    "        #         anomaly_list.append(self.pred_list_img_lvl[i])\n",
    "        #     else:\n",
    "        #         normal_list.append(self.pred_list_img_lvl[i])\n",
    "\n",
    "        # # thresholding\n",
    "        # # cal_confusion_matrix(self.gt_list_img_lvl, self.pred_list_img_lvl, img_path_list = self.img_path_list, thresh = 0.00097)\n",
    "        # # print()\n",
    "        # with open(args.project_root_path + r'/results.txt', 'a') as f:\n",
    "        #     f.write(args.category + ' : ' + str(values) + '\\n')\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='ANOMALYDETECTION')\n",
    "    parser.add_argument('--phase', choices=['train','test'], default='train')\n",
    "    parser.add_argument('--dataset_path', default=r'../../../../nas-files/mvtec/') # 'D:\\Dataset\\mvtec_anomaly_detection')#\n",
    "    parser.add_argument('--category', default='screw')\n",
    "    parser.add_argument('--num_epochs', default=1)\n",
    "    parser.add_argument('--batch_size', default=32)\n",
    "    parser.add_argument('--load_size', default=256) # 256\n",
    "    parser.add_argument('--input_size', default=224)\n",
    "    parser.add_argument('--coreset_sampling_ratio', default=0.01)\n",
    "    parser.add_argument('--project_root_path', default=r'./test') # 'D:\\Project_Train_Results\\mvtec_anomaly_detection\\210624\\test') #\n",
    "    parser.add_argument('--save_src_code', default=True)\n",
    "    parser.add_argument('--save_anomaly_map', default=True)\n",
    "    parser.add_argument('--n_neighbors', type=int, default=9)\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3099a69-7d5c-4aee-85db-36f3adb5b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottle\t carpet    leather\tmvtec\t    screw\ttransistor\n",
      "cable\t grid\t   license.txt\tpill\t    tile\twood\n",
      "capsule  hazelnut  metal_nut\treadme.txt  toothbrush\tzipper\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../nas-files/mvtec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93243f5b-9d70-4378-b7c4-6c9651c517ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Using cache found in /home/matthias/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/pytorch_lightning/trainer/optimizers.py:37: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name          | Type      | Params\n",
      "--------------------------------------------\n",
      "0 | model         | ResNet    | 68.9 M\n",
      "1 | criterion     | MSELoss   | 0     \n",
      "2 | inv_normalize | Normalize | 0     \n",
      "--------------------------------------------\n",
      "0         Trainable params\n",
      "68.9 M    Non-trainable params\n",
      "68.9 M    Total params\n",
      "275.533   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../nas-files/mvtec/screw/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa2b0b25d3d4460aeebb1b7611f3e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:145: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnson-Lindenstrauss lemma n_components auto\n",
      "Getting transformed features...\n",
      "Calculating distances... (250880, 306)\n",
      "Maximum distance from cluster centers is 0.25\n",
      "initial embedding size :  (250880, 1536)\n",
      "final embedding size :  (2508, 1536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../nas-files/mvtec/screw/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6bfa71f88f42ddb7042df936b98e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixel-level auc-roc score :\n",
      "0.8521706521586927\n",
      "Total image-level auc-roc score :\n",
      "0.6659151465464235\n",
      "test_epoch_end\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'img_auc': 0.6659151315689087, 'pixel_auc': 0.8521706461906433}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, default_root_dir=os.path.join(args.project_root_path, args.category), max_epochs=args.num_epochs, gpus=1) #, check_val_every_n_epoch=args.val_freq,  num_sanity_val_steps=0) # ,fast_dev_run=True)\n",
    "model = STPM(hparams=args)\n",
    "if args.phase == 'train':\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "elif args.phase == 'test':\n",
    "    trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e08e55-d13b-453b-961e-6621c79bef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = np.load(\"./embeddings/screw/total_embeddings.npy\")\n",
    "test = np.stack([np.load(f\"./embeddings/screw/test_embeddings_{i}.npy\") for i in range(160)])\n",
    "labels = np.concatenate([np.load(f\"./embeddings/screw/test_label_{i}.npy\") for i in range(160)])\n",
    "\n",
    "T = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd588d0-3a8a-4762-b81a-845f303681a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.patch_utils import *\n",
    "from sklearn.neighbors import LocalOutlierFactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c38262-adb5-44b8-9260-4906ad4353ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomprojector = SparseRandomProjection(n_components='auto', eps=0.9) # 'auto' => Johnson-Lindenstrauss lemma\n",
    "randomprojector.fit(train)\n",
    "\n",
    "selector = kCenterGreedy(train, 0, 0)\n",
    "selected_idx = selector.select_batch(model=randomprojector, already_selected=[], N=int(train.shape[0]*0.01))\n",
    "train_coreset = train[selected_idx]\n",
    "train.shape, train_coreset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ec72c-45d8-46f3-a3a6-fbdbb118bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scores_valid = patch_core_score(train_coreset, test[labels == 0].reshape(-1, train.shape[1]), T )\n",
    "scores_test = patch_core_score(train_coreset, test[labels == 1].reshape(-1, train.shape[1]), T )\n",
    "\n",
    "auc1 = roc_auc_score([0] * len(scores_valid) + [1] * len(scores_test), np.concatenate([scores_valid, scores_test]))        \n",
    "print(\"Total AUC\", auc1)\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=1, contamination=0.0001, novelty=True).fit(train_coreset[np.random.permutation(range(len(train_coreset)))])\n",
    "\n",
    "scores_valid = (-clf.score_samples(test[labels == 0].reshape(-1, train.shape[1])).reshape(-1, T)).max(1)\n",
    "scores_test = (-clf.score_samples(test[labels == 1].reshape(-1, train.shape[1])).reshape(-1, T)).max(1)\n",
    "\n",
    "auc1 = roc_auc_score([0] * len(scores_valid) + [1] * len(scores_test), np.concatenate([scores_valid, scores_test]))        \n",
    "print(\"Total AUC\", auc1)\n",
    "\n",
    "# >> Total AUC 0.9581881533101044\n",
    "# >> Total AUC 0.9078704652592745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14aceb-5fef-4b9e-8128-c9b2d6407f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff = get_wide_resnet(pooling=4)\n",
    "eff = eff.to(device)\n",
    "eff = eff.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dbca1-782b-42ee-a523-7bed54ceea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, X_valid_, X_test_, X_labels_, T = dataloader(clazz=13, P=8*28, s=14, label_per_patch=False, augment=False, size=224, normalize=False)\n",
    "\n",
    "X_val_ = X_[:10]\n",
    "X_ = X_[10:]\n",
    "\n",
    "X_ = concat_features(X_, eff, layers=[6,7], fmap_pool=True)\n",
    "X_valid_ = concat_features(X_valid_, eff, layers=[6,7], fmap_pool=True)\n",
    "X_test_ = concat_features(X_test_, eff, layers=[6,7], fmap_pool=True)\n",
    "X_val_ = concat_features(X_val_, eff, layers=[6,7], fmap_pool=True)\n",
    "\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6738b9d-86a5-48b0-94ba-90d021a1fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = fmap_to_patches(X_)\n",
    "X_valid_ = fmap_to_patches(X_valid_)\n",
    "X_test_ = fmap_to_patches(X_test_)\n",
    "X_val_ = fmap_to_patches(X_val_)\n",
    "X_val_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509ba1c-d724-4499-a09c-e3e42a08f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomprojector = SparseRandomProjection(n_components='auto', eps=0.9) # 'auto' => Johnson-Lindenstrauss lemma\n",
    "randomprojector.fit(X_)\n",
    "\n",
    "selector = kCenterGreedy(X_, 0, 0)\n",
    "selected_idx = selector.select_batch(model=randomprojector, already_selected=[], N=int(X_.shape[0]*0.01))\n",
    "train_coreset = X_[selected_idx]\n",
    "X_.shape, train_coreset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b449f4-760f-484b-8de9-d687726a63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 28*28 # n_tiles\n",
    "\n",
    "scores_valid = patch_core_score(train_coreset, X_valid_, T )\n",
    "scores_test = patch_core_score(train_coreset, X_test_, T )\n",
    "\n",
    "auc1 = roc_auc_score([0] * len(scores_valid) + [1] * len(scores_test), np.concatenate([scores_valid, scores_test]))        \n",
    "print(\"Total AUC\", auc1)\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=1, contamination=0.0001, novelty=True).fit(train_coreset)\n",
    "\n",
    "scores_valid = (-clf.score_samples(X_valid_).reshape(-1, T)).max(1)\n",
    "scores_test = (-clf.score_samples(X_test_).reshape(-1, T)).max(1)\n",
    "\n",
    "auc1 = roc_auc_score([0] * len(scores_valid) + [1] * len(scores_test), np.concatenate([scores_valid, scores_test]))        \n",
    "print(\"Total AUC\", auc1)\n",
    "\n",
    "# Total AUC 0.9243697478991597\n",
    "# Total AUC 0.9014142242262759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3eb56-e9ef-486d-a969-0a3251ea2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 26*26 # n_tiles\n",
    "\n",
    "scores_valid = patch_core_score(train_coreset, X_valid_, T )\n",
    "scores_test = patch_core_score(train_coreset, X_test_, T )\n",
    "\n",
    "auc1 = roc_auc_score([0] * len(scores_valid) + [1] * len(scores_test), np.concatenate([scores_valid, scores_test]))        \n",
    "print(\"Total AUC\", auc1)\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=1, contamination=0.0001, novelty=True).fit(train_coreset)\n",
    "\n",
    "scores_valid = (-clf.score_samples(X_valid_).reshape(-1, T)).max(1)\n",
    "scores_test = (-clf.score_samples(X_test_).reshape(-1, T)).max(1)\n",
    "\n",
    "auc1 = roc_auc_score([0] * len(scores_valid) + [1] * len(scores_test), np.concatenate([scores_valid, scores_test]))        \n",
    "print(\"Total AUC\", auc1)\n",
    "\n",
    "# Total AUC 0.9602377536380405\n",
    "# Total AUC 0.925804468128715"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
