{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b11a06-7976-4b4b-b4e2-a69e84dd4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.covariance import LedoitWolf, MinCovDet\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(252525)\n",
    "torch.manual_seed(252525)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from data.mvtec import *\n",
    "from hugeica import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8023d4ce-57bd-4f77-864e-039ea95b4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../gaussian-ad-mvtec/src/gaussian/\")\n",
    "sys.path.append(\"../../gaussian-ad-mvtec/src/common/utils\")\n",
    "\n",
    "from transparent import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a3da9-8d42-46e4-8dd5-e9798adea778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "(267, 14, 14, 160)\n",
      "(267, 31360)\n"
     ]
    }
   ],
   "source": [
    "bs = 50\n",
    "clazz = 3\n",
    "epochs = 1\n",
    "augment = False\n",
    "layer = 5\n",
    "\n",
    "net, input_size = build_transparent(\n",
    "            \"efficientnet-b4\",\n",
    "            pretrained=True,\n",
    "            extract_blocks=[0,1,2,3,4,5,6,7],\n",
    "            freeze=True,\n",
    "        )\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "X_, X_valid_, X_test_, X_labels_, T = zip(*[dataloader(clazz, P=224, s=224, label_per_patch=False, augment=augment) for i in range(epochs)])\n",
    "X_, X_valid_, X_test_ = np.concatenate(X_), np.concatenate(X_valid_), np.concatenate(X_test_)\n",
    "\n",
    "    \n",
    "X_ = torch.cat([ net(torch.from_numpy( X_[i:i+bs] ).to(device) ).detach().cpu()[layer] for i in range(0, len(X_), bs)]).cpu().numpy()\n",
    "X_valid_ = torch.cat([ net(torch.from_numpy( X_valid_[i:i+bs] ).to(device) ).detach().cpu()[layer] for i in range(0, len(X_valid_), bs)]).cpu().numpy()\n",
    "X_test_ = torch.cat([ net(torch.from_numpy( X_test_[i:i+bs] ).to(device) ).detach().cpu()[layer] for i in range(0, len(X_test_), bs)]).cpu().numpy()\n",
    "\n",
    "X_.mean(),X_.std()\n",
    "\n",
    "#mu = X_.mean(0)\n",
    "c = X_.shape[1]\n",
    "n = X_.shape[0]\n",
    "X__ = X_.transpose(0,2,3,1) # B, H, W, C\n",
    "#X__ = X__.reshape(n, -1, c).mean(1)\n",
    "print(X__.shape)\n",
    "X__ = X__.reshape(len(X__), -1)\n",
    "print(X__.shape)\n",
    "\n",
    "#pca = PCA(n_components=0.95, whiten=False).fit(X__)\n",
    "#class pca:\n",
    "#    transform = lambda x : x\n",
    "#X__ = pca.transform(X__)\n",
    "\n",
    "C_inv = LedoitWolf().fit(X__).precision_\n",
    "mu = X__.mean(0)\n",
    "\n",
    "# Pooling inliers\n",
    "n_valid = len(X_valid_)\n",
    "#X_valid_ = X_valid_.mean((2,3))\n",
    "X_valid_ = X_valid_.reshape(n_valid, -1)\n",
    "\n",
    "# Pooling outliers\n",
    "n_test = len(X_test_)\n",
    "X_test_ = X_test_.reshape(n_test, -1)\n",
    "#X_test_ = X_test_.mean((2,3))\n",
    "\n",
    "# Mahalanobis\n",
    "X_valid_ = X_valid_ - mu\n",
    "X_test_ = X_test_ - mu\n",
    "M_valid_ = ( X_valid_ * ( C_inv @ X_valid_.T ).T ).sum(1)    \n",
    "M_test_  = ( X_test_ * ( C_inv @ X_test_.T ).T ).sum(1)    \n",
    " \n",
    "\n",
    "scores_inliers = []\n",
    "scores_outliers = []\n",
    "\n",
    "scores_inliers.append(M_valid_)\n",
    "scores_outliers.append(M_test_)\n",
    "\n",
    "auc = roc_auc_score([0] * n_valid + [1] * n_test, np.concatenate([np.asarray(scores_inliers).sum(0), np.asarray(scores_outliers).sum(0)]))\n",
    "print(MVTEC.CLASSES[clazz], auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771e777-9911-413d-9d7e-40df4f459af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14eeeb3a-2b47-40c5-9365-b54dab25ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/matthias/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureExtractor(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU()\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU()\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU()\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU()\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU()\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU()\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU()\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU()\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU()\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU()\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (mean): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (sphering): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Add(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.register_parameter(name='mean', param=nn.Parameter(torch.zeros(dim).to(device)))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X + self.mean\n",
    "    \n",
    "    \n",
    "class Matmul(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.register_parameter(name='sphering', param=nn.Parameter(torch.eye(dim).to(device)))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return torch.matmul(X, self.sphering)\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, pooling=4):\n",
    "        super().__init__()\n",
    "        #\n",
    "        # Preparation\n",
    "        #\n",
    "        # Let's try to find the pooling layer positions\n",
    "        net = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True).features\n",
    "        net = net.to(device)\n",
    "        net.eval()\n",
    "        \n",
    "        self.idx_pooling_layer = []\n",
    "        for i, module in enumerate( net.modules() ):\n",
    "            if not isinstance(module, nn.Sequential):\n",
    "                if isinstance(module, nn.MaxPool2d):\n",
    "                    self.idx_pooling_layer.append(i)\n",
    "        self.F = self.idx_pooling_layer[pooling]\n",
    "        \n",
    "        #\n",
    "        # The final net\n",
    "        #\n",
    "        self.features = net[:self.F]\n",
    "        self.shape = self.features(torch.normal(0,1, (1, 3, 224, 224)).to(device)).shape\n",
    "        #self.mean = Add(self.shape[1])       \n",
    "        #self.sphering = Matmul(self.shape[1])\n",
    "        \n",
    "        self.mean = nn.Linear(self.shape[1], self.shape[1], bias=True).to(device)\n",
    "        self.sphering = nn.Linear(self.shape[1], self.shape[1], bias=False).to(device)\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "        # Sometimes inplace ReLUs cause problems with Laplace\n",
    "        for module in self.features.modules():\n",
    "            if not isinstance(module, nn.Sequential):\n",
    "                if isinstance(module, nn.ReLU):\n",
    "                    module.inplace = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.sphering.weight.data = torch.eye(self.shape[1]).to(device)\n",
    "        self.mean.weight.data = torch.eye(self.shape[1]).to(device)\n",
    "        self.mean.bias.data = torch.zeros(self.shape[1]).to(device)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.features(X)\n",
    "        X = X.mean((2,3)) # pooling the latents\n",
    "        X = self.mean(X)\n",
    "        X = self.sphering(X)\n",
    "        return X\n",
    "\n",
    "net = model = FeatureExtractor()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7c2f4a-662b-4d73-b71e-cac6b3b77bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplace import Laplace\n",
    "from laplace.utils import ModuleNameSubnetMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca436587-4b09-4126-a144-380c4e3abf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/matthias/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "bs = 25\n",
    "clazz = 13\n",
    "epochs = 50\n",
    "augment = True\n",
    "layer = 6\n",
    "\n",
    "net = FeatureExtractor(pooling=0)\n",
    "net = net.to(device)\n",
    "net.eval()\n",
    "\n",
    "for clazz in range(15):\n",
    "\n",
    "    net.reset()\n",
    "\n",
    "    #####################################################\n",
    "    #\n",
    "    # LOAD THE DATA\n",
    "    #####################################################\n",
    "    X_, X_valid_, X_test_, X_labels_, T = zip(*[dataloader(clazz, P=224, s=224, label_per_patch=False, augment=augment) for i in range(epochs)])\n",
    "    X_, X_valid_, X_test_ = np.concatenate(X_), np.concatenate(X_valid_), np.concatenate(X_test_)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X__ = torch.cat([ net(torch.from_numpy( X_[i:i+bs] ).to(device) ).detach().cpu() for i in range(0, len(X_), bs)]).cpu().numpy()\n",
    "        X_valid__ = torch.cat([ net(torch.from_numpy( X_valid_[i:i+bs] ).to(device) ).detach().cpu() for i in range(0, len(X_valid_), bs)]).cpu().numpy()\n",
    "        X_test__ = torch.cat([ net(torch.from_numpy( X_test_[i:i+bs] ).to(device) ).detach().cpu() for i in range(0, len(X_test_), bs)]).cpu().numpy()\n",
    "\n",
    "    #####################################################\n",
    "    #\n",
    "    # SPHERING FEATURE SPACE\n",
    "    #####################################################\n",
    "    k = 20\n",
    "    k_max = np.min(X__.shape)\n",
    "    pca = PCA(n_components=k_max, whiten=True).fit(X__)\n",
    "    sphering = pca.components_[-k:] / np.sqrt( pca.explained_variance_ )[-k:, None]\n",
    "    #sphering = pca.components_[:k] / np.sqrt( pca.explained_variance_ )[:k, None]\n",
    "    mu = X__.mean(0)\n",
    "    X__ = (sphering @ (X__ - mu).T).T\n",
    "\n",
    "    #sphering = pca.components_ / np.std(pca.explained_variance_)\n",
    "    net.mean.bias.data = -torch.from_numpy(mu).to(device)\n",
    "    # >>>>>>>>>> net.mean.weight.data = torch.eye(k).to(device)\n",
    "    net.sphering.weight.data = torch.from_numpy(sphering).contiguous().to(device)\n",
    "\n",
    "    #####################################################\n",
    "    #\n",
    "    # LAPLACE APPROXIMATION\n",
    "    #####################################################\n",
    "    lap_bs = 5\n",
    "    # >>>>>>>>>> k = len(mu)\n",
    "    X__ = torch.from_numpy(X_)\n",
    "    y__ = torch.zeros((len(X_), k))\n",
    "    dataset = torch.utils.data.TensorDataset(X__, y__)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=lap_bs)\n",
    "\n",
    "    model = net\n",
    "    subnetwork_mask = ModuleNameSubnetMask(model, module_names=[\"features.0\"])\n",
    "    subnetwork_mask.select()\n",
    "    subnetwork_indices = subnetwork_mask.indices.to(\"cpu\")\n",
    "\n",
    "    la = Laplace(model, subset_of_weights='last_layer', # diag', 'kron', 'full', 'lowrank' {'last_layer', 'subnetwork', 'all'}\n",
    "                 hessian_structure='full', likelihood='regression',\n",
    "                 subnetwork_indices=subnetwork_indices\n",
    "                )\n",
    "    la.fit(train_loader)\n",
    "\n",
    "    #####################################################\n",
    "    #\n",
    "    # COMPUTE SCORES\n",
    "    #####################################################\n",
    "    f_mu_in, f_var_in   = zip(*[la(torch.from_numpy( X_valid_[i:i+lap_bs] ).to(device) ) for i in range(0, len(X_valid_), lap_bs)])\n",
    "    f_mu_in, f_var_in   = torch.cat(f_mu_in).cpu().numpy(), torch.cat(f_var_in).cpu().numpy()\n",
    "    \n",
    "    f_mu_out, f_var_out = zip(*[la(torch.from_numpy( X_test_[i:i+lap_bs] ).to(device) ) for i in range(0, len(X_test_), lap_bs)])\n",
    "    f_mu_out, f_var_out = torch.cat(f_mu_out).cpu().numpy(), torch.cat(f_var_out).cpu().numpy()\n",
    "\n",
    "    # Aggregate scores\n",
    "    scores_inliers = []\n",
    "    scores_outliers = []\n",
    "    scores_inliers.append(np.linalg.norm(f_mu_in, axis=1))\n",
    "    scores_outliers.append(np.linalg.norm(f_mu_out, axis=1))\n",
    "\n",
    "    auc = roc_auc_score([0] * len(f_mu_in) + [1] * len(f_mu_out), np.concatenate([np.asarray(scores_inliers).sum(0), np.asarray(scores_outliers).sum(0)]))\n",
    "    print(\"PPD-mean (AUC)\", MVTEC.CLASSES[clazz], auc)\n",
    "\n",
    "    # Aggregate scores\n",
    "    scores_inliers = []\n",
    "    scores_outliers = []\n",
    "    scores_inliers.append(f_var_in.sum((1,2)))\n",
    "    scores_outliers.append(f_var_out.sum((1,2)))\n",
    "\n",
    "    auc = roc_auc_score([0] * len(f_mu_in) + [1] * len(f_mu_out), np.concatenate([np.asarray(scores_inliers).sum(0), np.asarray(scores_outliers).sum(0)]))\n",
    "    print(\"PPD-var (AUC)\", MVTEC.CLASSES[clazz], auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbb83d-d839-4134-bc58-875e99b5c7cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_627648/3269226641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'auc' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
