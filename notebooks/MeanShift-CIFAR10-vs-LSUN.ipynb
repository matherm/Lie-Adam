{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Downloading bedroom val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4561k  100 4561k    0     0  2786k      0  0:00:01  0:00:01 --:--:-- 2784k\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from data.mnist_novelty import MNIST_OneClass\n",
    "from data.cifar_novelty import Cifar10_OneClass\n",
    "from hugeica import *\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(252525)\n",
    "torch.manual_seed(252525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from urllib.request import Request, urlopen\n",
    "from os.path import join\n",
    "import zipfile\n",
    "\n",
    "def list_categories():\n",
    "    url = 'http://dl.yf.io/lsun/categories.txt'\n",
    "    with urlopen(Request(url)) as response:\n",
    "        return response.read().decode().strip().split('\\n')\n",
    "\n",
    "\n",
    "def download(out_dir, category, set_name):\n",
    "    url = 'http://dl.yf.io/lsun/scenes/{category}_' \\\n",
    "          '{set_name}_lmdb.zip'.format(**locals())\n",
    "    if set_name == 'test':\n",
    "        out_name = 'test_lmdb.zip'\n",
    "        url = 'http://dl.yf.io/lsun/scenes/{set_name}_lmdb.zip'\n",
    "    else:\n",
    "        out_name = '{category}_{set_name}_lmdb.zip'.format(**locals())\n",
    "    out_path = join(out_dir, out_name)\n",
    "    cmd = ['curl', url, '-o', out_path]\n",
    "    print('Downloading', category, set_name, 'set')\n",
    "    subprocess.call(cmd)\n",
    "    \n",
    "list_categories()\n",
    "download(\"./data\", \"bedroom\", \"val\")\n",
    "\n",
    "zipf = zipfile.ZipFile(\"./data/bedroom_val_lmdb.zip\")\n",
    "zipf.extractall(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "svhn = torchvision.datasets.SVHN(\"./data\", split='train', transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "cifar10 = torchvision.datasets.CIFAR10(\"./data\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "cifar10_test = torchvision.datasets.CIFAR10(\"./data\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "lsun =  torchvision.datasets.LSUN(root='./data', classes=['bedroom_val'], transform=transforms.Compose([transforms.CenterCrop((200, 200)), transforms.Resize((32,32)), transforms.ToTensor()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X, X_in, X_out, norm_contrast=True, DC=True, channels=None):\n",
    "    \n",
    "    #DEQUANTIZE\n",
    "    X_, _ = dequantize(X) \n",
    "    \n",
    "    # CONTRAST\n",
    "    if norm_contrast:\n",
    "        X_, _ = to_norm_contrast(X_, DC=DC, channels=channels)\n",
    "    mean, std = np.zeros(X_.mean(0).shape), X_.std()\n",
    "\n",
    "    # SCALE\n",
    "    X_, _ = scale(X_, mean, std)\n",
    "    \n",
    "    X_in_, _ = dequantize(X_in)\n",
    "    if norm_contrast:\n",
    "        X_in_, _ = to_norm_contrast(X_in_, DC=DC, channels=channels)\n",
    "    X_in_, _ = scale(X_in_, mean, std)\n",
    "\n",
    "    X_out_, _ = dequantize(X_out)\n",
    "    if norm_contrast:\n",
    "        X_out_, _ = to_norm_contrast(X_out_, DC=DC, channels=channels)\n",
    "    \n",
    "    X_out_, _ = scale(X_out_, mean, std)\n",
    "    return X_, X_in_, X_out_, mean, std\n",
    "\n",
    "def augment(X):\n",
    "    X = torch.stack( [ transforms.ToTensor()( TF.rotate(transforms.ToPILImage()(  torch.from_numpy(x.reshape(3,32,32))  ), [90, 180, 270, 0][np.random.randint(4)]) )  for x in X ] )\n",
    "    return X.reshape(len(X), -1)\n",
    "\n",
    "def augment_rot(X, rot = [0, 90, 180, 270]):\n",
    "    X_aug = []\n",
    "    for x in X:\n",
    "        for r in rot:\n",
    "             X_aug += [transforms.ToTensor()( TF.rotate(transforms.ToPILImage()(  torch.from_numpy(x.reshape(3,32,32))  ) , r) )]\n",
    "    X = torch.stack( X_aug)\n",
    "    return X.reshape(len(X), -1)\n",
    "\n",
    "def augment_trans(X, trans = range(-8, 8)):\n",
    "    X = torch.stack( [torch.from_numpy(  np.roll(x.reshape(3, 32, 32), int(np.random.uniform(-2, 2)), 1))  for x in X] )\n",
    "    X = torch.stack( [torch.from_numpy(  np.roll(x.reshape(3, 32, 32), int(np.random.uniform(-2, 2)), 2))  for x in X] )\n",
    "    return X.reshape(len(X), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cifar = torch.stack([x for x,y in cifar10]).numpy()\n",
    "X_cifar = X_cifar[np.random.permutation(int(0.1*len(X_cifar)))]\n",
    "X_cifar_test = torch.stack([x for x,y in cifar10_test]).numpy()\n",
    "X_svhn  = torch.stack([x for x,y in svhn]).numpy()\n",
    "X_lsun  = torch.stack([x for x,y in lsun]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=588 > np.min([max_components=256,bs=10000]). Setting n_components=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/hugeica-0.8.0-py3.9.egg/hugeica/nn/Layer_SO.py:46: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:1937.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit HugeICA((500000, 588, 256), device='cuda', bs=10000)\n",
      "  4%|████████▋                                                                                                                                                                                                                 | 2/50 [00:00<00:15,  3.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/.conda/envs/pytorch3/lib/python3.9/site-packages/hugeica-0.8.0-py3.9.egg/hugeica/helpers/expm32.py:262: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 49/50 [00:06<00:00,  7.16it/s]\n",
      "Ep.  0 - -1.0039 - validation (loss/white/kurt/mi/logp): -1.0036 / 0.02 / 6.66 / 1.2195 / 0.3690 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(16).\n",
      "# Fit HugeICA((500000, 588, 16), device='cuda', bs=10000)\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 49/50 [00:05<00:00,  8.74it/s]\n",
      "Ep.  0 - -0.9529 - validation (loss/white/kurt/mi/logp): -0.9550 / 0.04 / 4.18 / 0.0537 / 0.3661 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(16).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "Warning: bs=10000 is not a multiple of n_tiles=64. Setting bs=9984\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=972 > np.min([max_components=256,bs=9984]). Setting n_components=256\n",
      "# Fit HugeICA((329472, 972, 256), device='cuda', bs=9984)\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 32/33 [00:09<00:00,  3.41it/s]\n",
      "Ep.  0 - -1.0013 - validation (loss/white/kurt/mi/logp): -1.0009 / 0.02 / 4.80 / 0.7965 / 0.3834 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(24).\n",
      "# Fit HugeICA((329472, 972, 24), device='cuda', bs=9984)\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 32/33 [00:07<00:00,  4.03it/s]\n",
      "Ep.  0 - -0.9471 - validation (loss/white/kurt/mi/logp): -0.9465 / 0.04 / 3.68 / 0.0643 / 0.3723 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(24).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "Warning: bs=10000 is not a multiple of n_tiles=36. Setting bs=9972\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=1452 > np.min([max_components=256,bs=9972]). Setting n_components=256\n",
      "# Fit HugeICA((189468, 1452, 256), device='cuda', bs=9972)\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 18/19 [00:10<00:00,  1.68it/s]\n",
      "Ep.  0 - -0.9943 - validation (loss/white/kurt/mi/logp): -0.9936 / 0.03 / 3.49 / 0.5445 / 0.3904 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(31).\n",
      "# Fit HugeICA((189468, 1452, 31), device='cuda', bs=9972)\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 18/19 [00:08<00:00,  2.02it/s]\n",
      "Ep.  0 - -0.9254 - validation (loss/white/kurt/mi/logp): -0.9231 / 0.05 / 3.13 / 0.0643 / 0.3771 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(31).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=2028 > np.min([max_components=256,bs=10000]). Setting n_components=256\n",
      "# Fit HugeICA((80000, 2028, 256), device='cuda', bs=10000)\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 7/8 [00:09<00:01,  1.40s/it]\n",
      "Ep.  0 - -0.9754 - validation (loss/white/kurt/mi/logp): -0.9712 / 0.04 / 2.62 / 0.3781 / 0.3995 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(36).\n",
      "# Fit HugeICA((80000, 2028, 36), device='cuda', bs=10000)\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 7/8 [00:08<00:01,  1.23s/it]\n",
      "Ep.  0 - -0.8820 - validation (loss/white/kurt/mi/logp): -0.8674 / 0.07 / 2.56 / 0.0588 / 0.3797 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(36).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=2700 > np.min([max_components=256,bs=10000]). Setting n_components=256\n",
      "# Fit HugeICA((20000, 2700, 256), device='cuda', bs=10000)\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 1/2 [00:05<00:05,  5.44s/it]\n",
      "Ep.  0 - -0.9406 - validation (loss/white/kurt/mi/logp): -0.8688 / 0.08 / 1.92 / 0.2720 / 0.4036 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(37).\n",
      "# Fit HugeICA((20000, 2700, 37), device='cuda', bs=10000)\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 1/2 [00:05<00:05,  5.15s/it]\n",
      "Ep.  0 - -0.8967 - validation (loss/white/kurt/mi/logp): -0.7820 / 0.10 / 1.98 / 0.0460 / 0.3782 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(37).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "0\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=588 > np.min([max_components=256,bs=10000]). Setting n_components=256\n",
      "# Fit HugeICA((500000, 588, 256), device='cuda', bs=10000)\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 49/50 [00:06<00:00,  7.61it/s]\n",
      "Ep.  0 - -1.0039 - validation (loss/white/kurt/mi/logp): -1.0036 / 0.02 / 6.68 / 1.2234 / 0.3688 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(16).\n",
      "# Fit HugeICA((500000, 588, 16), device='cuda', bs=10000)\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 49/50 [00:05<00:00,  8.67it/s]\n",
      "Ep.  0 - -0.9529 - validation (loss/white/kurt/mi/logp): -0.9550 / 0.04 / 4.18 / 0.0536 / 0.3662 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(16).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "Warning: bs=10000 is not a multiple of n_tiles=64. Setting bs=9984\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=972 > np.min([max_components=256,bs=9984]). Setting n_components=256\n",
      "# Fit HugeICA((329472, 972, 256), device='cuda', bs=9984)\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 32/33 [00:09<00:00,  3.42it/s]\n",
      "Ep.  0 - -1.0013 - validation (loss/white/kurt/mi/logp): -1.0009 / 0.02 / 4.79 / 0.7948 / 0.3835 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(24).\n",
      "# Fit HugeICA((329472, 972, 24), device='cuda', bs=9984)\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 32/33 [00:07<00:00,  4.07it/s]\n",
      "Ep.  0 - -0.9471 - validation (loss/white/kurt/mi/logp): -0.9465 / 0.04 / 3.68 / 0.0642 / 0.3723 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(24).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "Warning: bs=10000 is not a multiple of n_tiles=36. Setting bs=9972\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=1452 > np.min([max_components=256,bs=9972]). Setting n_components=256\n",
      "# Fit HugeICA((189468, 1452, 256), device='cuda', bs=9972)\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 18/19 [00:10<00:00,  1.68it/s]\n",
      "Ep.  0 - -0.9943 - validation (loss/white/kurt/mi/logp): -0.9936 / 0.03 / 3.49 / 0.5439 / 0.3903 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(31).\n",
      "# Fit HugeICA((189468, 1452, 31), device='cuda', bs=9972)\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 18/19 [00:08<00:00,  2.03it/s]\n",
      "Ep.  0 - -0.9254 - validation (loss/white/kurt/mi/logp): -0.9227 / 0.05 / 3.05 / 0.0608 / 0.3781 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(31).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=2028 > np.min([max_components=256,bs=10000]). Setting n_components=256\n",
      "# Fit HugeICA((80000, 2028, 256), device='cuda', bs=10000)\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 7/8 [00:09<00:01,  1.40s/it]\n",
      "Ep.  0 - -0.9754 - validation (loss/white/kurt/mi/logp): -0.9712 / 0.04 / 2.61 / 0.3764 / 0.3995 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(36).\n",
      "# Fit HugeICA((80000, 2028, 36), device='cuda', bs=10000)\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 7/8 [00:08<00:01,  1.24s/it]\n",
      "Ep.  0 - -0.8820 - validation (loss/white/kurt/mi/logp): -0.8674 / 0.07 / 2.55 / 0.0587 / 0.3797 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(36).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "# Fit SpatialICA(q90).\n",
      "Warning: n_components=2700 > np.min([max_components=256,bs=10000]). Setting n_components=256\n",
      "# Fit HugeICA((20000, 2700, 256), device='cuda', bs=10000)\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 1/2 [00:05<00:05,  5.49s/it]\n",
      "Ep.  0 - -0.9406 - validation (loss/white/kurt/mi/logp): -0.8688 / 0.08 / 1.91 / 0.2681 / 0.4038 (eval took: 0.0s)\n",
      "# Re-Fit SpatialICA(37).\n",
      "# Fit HugeICA((20000, 2700, 37), device='cuda', bs=10000)\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 1/2 [00:05<00:05,  5.30s/it]\n",
      "Ep.  0 - -0.8967 - validation (loss/white/kurt/mi/logp): -0.7820 / 0.10 / 1.98 / 0.0459 / 0.3783 (eval took: 0.0s)\n",
      "# Compute ICA metrics.\n",
      "# Fit SFA(37).\n",
      "# Compute information measures\n",
      "# Compute AUCs\n",
      "# Compute Spread\n",
      "# Compute Entropy\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "log_full = []\n",
    "for ood in [X_svhn, X_lsun]:\n",
    "\n",
    "    #X_ = augment_rot(X_)\n",
    "    #X_ = augment_trans(X_)\n",
    "    \n",
    "    #X_valid_ = augment_rot(X_valid_)\n",
    "    #X_valid_ = augment_trans(X_valid_)\n",
    "    \n",
    "    #_test_ = augment_rot(X_test_)\n",
    "    #X_test_ = augment_trans(X_test_)\n",
    "\n",
    "    hyp2 = SFA.hyperparameter_search(X_cifar, X_cifar_test, ood, \n",
    "                      patch_size=range(14,31,4),\n",
    "                      n_components=[\"q90\"], \n",
    "                      stride=[2], \n",
    "                      shape=(3,32,32), \n",
    "                      bs=10000, \n",
    "                      lr=1e-4,\n",
    "                      epochs=20,\n",
    "                      norm=[2],\n",
    "                      mode=\"ta\",\n",
    "                      max_components=256,\n",
    "                      remove_components=[0],\n",
    "                      use_conv=False,\n",
    "                      logging=1, \n",
    "                      aucs=[\"mean\"]) \n",
    "    log_full.append(hyp2)\n",
    "    print(clazz)\n",
    "    \n",
    "concat = pd.concat(log_full)\n",
    "concat[\"class\"] = np.repeat(np.arange(len(log_full)), len(log_full[0]))\n",
    "concat.to_csv(f\"./experiments/cifar10_ood_hyperparameter_search_q90_ta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>k</th>\n",
       "      <th>-H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.446164</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.056304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.514605</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.055665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.480384</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.055984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  patch_size     k        -H\n",
       "0  0.446164        26.0  36.0  0.056304\n",
       "1  0.514605        26.0  36.0  0.055665\n",
       "2  0.480384        26.0  36.0  0.055984"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(\"./experiments/cifar10_ood_hyperparameter_search_q90_ta.csv\")\n",
    "\n",
    "df = []\n",
    "for i in range(2):\n",
    "    l = log[log[\"class\"] == i]\n",
    "    l = l[l[\"nor\"] == 2]\n",
    "    df.append((l.sort_values(\"mean\", ascending=False)[\"mean\"].head(1).item(),\n",
    "              l.sort_values(\"negH_sum\", ascending=False)[\"patch_size\"].head(1).item(),\n",
    "              l.sort_values(\"negH_sum\", ascending=False)[\"n_components\"].head(1).item(),\n",
    "              l.sort_values(\"negH_sum\", ascending=False)[\"negH_sum\"].head(1).item()))\n",
    "\n",
    "df.append(tuple(np.asarray(df).mean(0)))\n",
    "pd.DataFrame(df, columns=[\"score\", \"patch_size\", \"k\", \"-H\"] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
