{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4df05626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bottle',\n",
       " 'carpet',\n",
       " 'leather',\n",
       " 'pill',\n",
       " 'tile',\n",
       " 'wood',\n",
       " 'cable',\n",
       " 'grid',\n",
       " 'toothbrush',\n",
       " 'zipper',\n",
       " 'capsule',\n",
       " 'hazelnut',\n",
       " 'metal_nut',\n",
       " 'screw',\n",
       " 'transistor']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models as mods\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.covariance import LedoitWolf, MinCovDet\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from data.mvtec import *\n",
    "inv_norm = MVTEC().inv_normalize\n",
    "\n",
    "from hugeica import *\n",
    "from models.backbones import *\n",
    "\n",
    "np.random.seed(252525)\n",
    "torch.manual_seed(252525)\n",
    "\n",
    "MVTEC_PATH=\"/home/ios/data/mvtec\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MVTEC.CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d53ad96",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27744/2623543499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclazz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     X_, X_valid_, X_test_, X_labels_, T = dataloader(clazz, P=224, s=224, label_per_patch=False, load_size=256, crop_size=224, normalize=False,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                                      MVTEC_PATH=MVTEC_PATH )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repos/fasterica/notebooks/data/mvtec.py\u001b[0m in \u001b[0;36mdataloader\u001b[0;34m(clazz, P, s, label_per_patch, MVTEC_PATH, augment, load_size, crop_size, normalize)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mX_valid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVTEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inlier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclazz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mX_valid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_valid_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVTEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"outlier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclazz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repos/fasterica/notebooks/data/mvtec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mX_valid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVTEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inlier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclazz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mX_valid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_valid_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVTEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"outlier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMVTEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclazz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repos/fasterica/notebooks/data/mvtec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m#im = imread()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch3/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \"\"\"\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch3/lib/python3.9/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bs = 50\n",
    "p = 5 # fallback patch_size\n",
    "s = 1 # stride\n",
    "\n",
    "net = mods.efficientnet_b4(pretrained=True).features\n",
    "net = net.to(device)\n",
    "net.eval()\n",
    "\n",
    "for clazz in [14]:\n",
    "    \n",
    "    X_, X_valid_, X_test_, X_labels_, T = dataloader(clazz, P=224, s=224, label_per_patch=False, load_size=256, crop_size=224, normalize=False,\n",
    "                                                     MVTEC_PATH=MVTEC_PATH )\n",
    "    \n",
    "    X_test_images = X_test_\n",
    "\n",
    "    X = concat_features(X_, net, layers=[5,6], fmap_pool=False)\n",
    "    X_valid = concat_features(X_valid_, net, layers=[5,6], fmap_pool=False)\n",
    "    X_test = concat_features(X_test_, net, layers=[5,6], fmap_pool=False)\n",
    "\n",
    "    shapes = (X.shape, X_test.shape, X_valid.shape)\n",
    "    c = X.shape[1]\n",
    "    t = X.shape[2] # tile_size\n",
    "    n = len(X_valid) + len(X_test)\n",
    "    print(shapes)\n",
    "    \n",
    "    for i,j in enumerate(range(1, len(X), 5)):\n",
    "    \n",
    "        model = SFA(shape=(c, t, t), \n",
    "                        BSZ=(p, p), \n",
    "                        stride=s, \n",
    "                        n_components=\"q9999\",\n",
    "                        remove_components=0,\n",
    "                        max_components=5000,\n",
    "                        min_components=10,\n",
    "                        mode=\"ta\")\n",
    "\n",
    "        model.fit(X[:j], 1, bs=5000, lr=1e-3, logging=-10)\n",
    "\n",
    "        #auc_g, tg       = auc_global_mean_shift(model, X_valid, X_test)\n",
    "        auc_l, tl       = auc_local_mean_shift(model, X, X_valid, X_test, size=2)\n",
    "        #auc_c, tc, cset = auc_cluster_mean_shift(model, X, X_valid, X_test, True, return_coreset=True)\n",
    "        #auc_cc, tcc     = auc_cluster_mean_shift(model, X, X_valid, X_test, False, k=len(cset))\n",
    "        #auc_s, ts       = auc_sources_mean_shift(model, X, X_valid, X_test)\n",
    "        #auc_cs, tcs     = auc_coreset(X, X_valid, X_test)\n",
    "\n",
    "        #df = pd.DataFrame(np.asarray([clazz, auc_g, auc_l, auc_c, auc_cc, auc_s, n/tg, n/tl, n/tc, n/tcc, n/ts, p, t, model.model.n_components])[:, None].T, \n",
    "        #                  columns=[\"class\", \"AUC-g\", \"AUC-l\", \"AUC-c\", \"AUC-cc\", \"AUC-s\", \"fps-g\", \"fps-l\", \"fps-c\", \"fps-cc\", \"fps-s\", \"p_size\", \"t\", \"n_components\"]) \n",
    "\n",
    "        map_i, map_o = local_mean_shift(model, X, X_valid, X_test, size=2)\n",
    "        anomaly_map = make_anomaly_map(map_i, map_o)[1]\n",
    "        anomaly_map = anomaly_map + X_test_images\n",
    "        \n",
    "\n",
    "        im_test  = torchvision.utils.make_grid(torch.from_numpy(anomaly_map), nrow=10, normalize=True,  value_range=(0,  1), rscale_each=False , padding=3 )\n",
    "\n",
    "        n_rows_test = len(X_test_images)//10\n",
    "        n_cols_train = 1 + len(X_)//n_rows_test\n",
    "        if j < n_cols_train:\n",
    "            trn = np.concatenate([X_[:j], np.zeros_like(X_[:1]).repeat(n_cols_train - j, axis=0)], axis=0)\n",
    "        else:\n",
    "            trn = X_[:j]\n",
    "        im_train = torchvision.utils.make_grid(torch.from_numpy(trn), nrow=n_cols_train, normalize=True,  value_range=(0,  1), rscale_each=False , padding=3 )\n",
    "\n",
    "        margin = 100\n",
    "        im_train_ = np.zeros((3, im_test.shape[1], im_train.shape[2] + margin ))\n",
    "        im_train_[:, :im_train.shape[1], margin:margin+im_train.shape[2]] = im_train\n",
    "\n",
    "        f = plt.figure(figsize=(15,5)) #figure with correct aspect ratio\n",
    "        ax = plt.axes((0,0,1,1)) #axes over whole figure\n",
    "        ax.imshow(np.concatenate([im_test, im_train_], axis=2).transpose(1,2,0))\n",
    "        x,y = im_test.shape[2] + im_train_.shape[2] - 550, im_train_.shape[1] - 100\n",
    "        ax.text(x,y, f\"AUC = {auc_l:.2f}\", bbox=dict(fill=\"white\", edgecolor='red', linewidth=2), size=\"medium\")\n",
    "        ax.axis('off')\n",
    "        _ = f.savefig(f\"im_{clazz}_{i:03d}.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a457af7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ios/anaconda3/envs/pytorch3 --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from 'im_13_%3d.png':\n",
      "  Duration: 00:00:02.56, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgba(pc), 4500x1500 [SAR 11811:11811 DAR 3:1], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mprofile High, level 5.1, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0m264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=24 lookahead_threads=4 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=1 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'out.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 4500x1500 [SAR 1:1 DAR 3:1], q=-1--1, 1 fps, 16384 tbn, 1 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=   32 fps= 14 q=-1.0 Lsize=    1372kB time=00:00:29.00 bitrate= 387.6kbits/s speed=12.9x    \n",
      "video:1371kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.085132%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mframe I:1     Avg QP:10.35  size:307772\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mframe P:10    Avg QP:11.83  size:102653\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mframe B:21    Avg QP:16.48  size:  3273\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mconsecutive B-frames:  6.2%  0.0% 56.2% 37.5%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mmb I  I16..4: 21.6% 66.0% 12.4%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mmb P  I16..4:  1.1%  2.1%  3.3%  P16..4:  7.2%  1.1%  1.5%  0.0%  0.0%    skip:83.7%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  5.5%  0.2%  0.0%  direct: 0.2%  skip:94.1%  L0:39.8% L1:59.1% BI: 1.1%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0m8x8 transform intra:52.5% inter:68.6%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mcoded y,uvDC,uvAC intra: 47.9% 12.3% 11.3% inter: 2.3% 3.0% 1.0%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mi16 v,h,dc,p: 58% 23%  7% 12%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 73%  6%  4%  2%  3%  3%  3%  3%  3%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 24%  8%  6%  9%  7%  9%  7%  6%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mi8c dc,h,v,p: 91%  4%  4%  1%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mref P L0: 78.6%  3.0% 13.1%  5.2%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mref B L0: 84.1% 14.7%  1.2%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mref B L1: 92.7%  7.3%\n",
      "\u001b[1;36m[libx264 @ 0x55ec946d0840] \u001b[0mkb/s:350.76\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -r 2 -i im_13_%3d.png -c:v libx264 -vf fps=1 -pix_fmt yuv420p out.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 50\n",
    "p = 4 # fallback patch_size\n",
    "s = 1 # stride\n",
    "\n",
    "net = mods.efficientnet_b4(pretrained=True).features\n",
    "net = net.to(device)\n",
    "net.eval()\n",
    "\n",
    "for clazz in [13]:\n",
    "    \n",
    "    X_, X_valid_, X_test_, X_labels_, T = dataloader(clazz, P=224, s=224, label_per_patch=False, load_size=256, crop_size=224, normalize=False)\n",
    "\n",
    "    X = concat_features(X_, net, layers=[5,6], fmap_pool=False)\n",
    "    X_valid = concat_features(X_valid_, net, layers=[5,6], fmap_pool=False)\n",
    "    X_test = concat_features(X_test_, net, layers=[5,6], fmap_pool=False)\n",
    "\n",
    "    shapes = (X.shape, X_test.shape, X_valid.shape)\n",
    "    c = X.shape[1]\n",
    "    t = X.shape[2] # tile_size\n",
    "    n = len(X_valid) + len(X_test)\n",
    "    print(shapes)\n",
    "    \n",
    "    model = SFA(shape=(c, t, t), \n",
    "                    BSZ=(p, p), \n",
    "                    stride=s, \n",
    "                    n_components=\"q9999\",\n",
    "                    remove_components=0,\n",
    "                    max_components=5000,\n",
    "                    min_components=100,\n",
    "                    mode=\"ta\")\n",
    "\n",
    "    model.fit(X, 1, bs=5000, lr=1e-3, logging=-10)\n",
    "    \n",
    "    auc_g, tg       = auc_global_mean_shift(model, X_valid, X_test)\n",
    "    auc_l, tl       = auc_local_mean_shift(model, X, X_valid, X_test, size=2)\n",
    "    auc_c, tc, cset = auc_cluster_mean_shift(model, X, X_valid, X_test, True, return_coreset=True)\n",
    "    auc_cc, tcc     = auc_cluster_mean_shift(model, X, X_valid, X_test, False, k=len(cset))\n",
    "    auc_s, ts       = auc_sources_mean_shift(model, X, X_valid, X_test)\n",
    "    #auc_cs, tcs     = auc_coreset(X, X_valid, X_test)\n",
    "\n",
    "    df = pd.DataFrame(np.asarray([clazz, auc_g, auc_l, auc_c, auc_cc, auc_s, n/tg, n/tl, n/tc, n/tcc, n/ts, p, t, model.model.n_components])[:, None].T, \n",
    "                      columns=[\"class\", \"AUC-g\", \"AUC-l\", \"AUC-c\", \"AUC-cc\", \"AUC-s\", \"fps-g\", \"fps-l\", \"fps-c\", \"fps-cc\", \"fps-s\", \"p_size\", \"t\", \"n_components\"]) \n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (25, 25)\n",
    "    map_i, map_o = local_mean_shift(model, X, X_valid, X_test, size=2)\n",
    "    anomaly_map = make_anomaly_map(map_i, map_o)[1]\n",
    "    anomaly_map = anomaly_map + X_test_images\n",
    "    show( torchvision.utils.make_grid(torch.from_numpy(anomaly_map), nrow=10, normalize=True,  value_range=(0,  1), rscale_each=False , padding=3 ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
